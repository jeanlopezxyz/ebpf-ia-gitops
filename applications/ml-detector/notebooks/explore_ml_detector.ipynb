{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Exploraci√≥n del ML Detector\n",
    "\n",
    "## Objetivo\n",
    "Este notebook explora y visualiza el funcionamiento del sistema de detecci√≥n de amenazas basado en Machine Learning.\n",
    "\n",
    "## ¬øQu√© hace este notebook?\n",
    "- **Instancia el `ThreatDetector`**: Usa el c√≥digo real del proyecto sin duplicarlo\n",
    "- **Genera datos sint√©ticos**: Crea muestras de tr√°fico normal y an√≥malo para entrenamiento\n",
    "- **Entrena modelos ML**: Ejecuta algoritmos KMeans, LOF y OneClassSVM\n",
    "- **Visualiza resultados**: Proyecta datos 6D a 2D usando PCA para an√°lisis visual\n",
    "- **Eval√∫a detecci√≥n**: Prueba la capacidad de detecci√≥n con muestras de prueba\n",
    "\n",
    "## Casos de uso que simula:\n",
    "- **Tr√°fico normal**: Patrones t√≠picos de red con variabilidad natural\n",
    "- **DDoS**: Alto volumen de paquetes desde pocas IPs\n",
    "- **Port Scanning**: Muchos puertos √∫nicos desde pocas IPs  \n",
    "- **Data Exfiltration**: Alto volumen de bytes con pocos puertos\n",
    "\n",
    "## Requisitos\n",
    "Instalar dependencias de desarrollo: `pip install -r applications/ml-detector/requirements-dev.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n del entorno\n",
    "\n",
    "**¬øQu√© hace esta secci√≥n?**\n",
    "- Configura las rutas para importar el c√≥digo del proyecto ML Detector\n",
    "- Desactiva el entrenamiento autom√°tico para tener control manual\n",
    "- Configura matplotlib para visualizaciones de alta calidad\n",
    "\n",
    "**¬øPor qu√© es importante?**\n",
    "- Permite usar el c√≥digo real del detector sin duplicarlo\n",
    "- Evita entrenamientos autom√°ticos que podr√≠an interferir con la exploraci√≥n\n",
    "- Asegura que las visualizaciones se muestren correctamente en el notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar ruta para importar m√≥dulos del proyecto\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Asume que este notebook vive en applications/ml-detector/notebooks\n",
    "nb_dir = Path.cwd()\n",
    "app_dir = nb_dir.parent  # applications/ml-detector\n",
    "sys.path.insert(0, str(app_dir))\n",
    "\n",
    "# Desactivar entrenamiento/baseline autom√°ticos para exploraci√≥n reproducible\n",
    "# Esto permite controlar manualmente cu√°ndo entrenar los modelos\n",
    "os.environ['TRAINING_ENABLED'] = 'false'\n",
    "os.environ['BASELINE_ENABLED'] = 'false'\n",
    "os.environ.setdefault('MODEL_PATH', '/tmp/models')\n",
    "\n",
    "# Configurar matplotlib para visualizaciones de alta calidad\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-section",
   "metadata": {},
   "source": [
    "## 2. Inicializaci√≥n del detector\n",
    "\n",
    "**¬øQu√© hace esta secci√≥n?**\n",
    "- Importa las librer√≠as necesarias para an√°lisis de datos y visualizaci√≥n\n",
    "- Crea una instancia del `ThreatDetector` real del proyecto\n",
    "- Verifica el estado inicial del detector (sin entrenar)\n",
    "\n",
    "**Librer√≠as utilizadas:**\n",
    "- `numpy`: Operaciones num√©ricas y matrices\n",
    "- `matplotlib.pyplot`: Gr√°ficos y visualizaciones\n",
    "- `seaborn`: Visualizaciones estad√≠sticas avanzadas\n",
    "- `sklearn.decomposition.PCA`: Reducci√≥n de dimensionalidad\n",
    "- `detector.ThreatDetector`: Clase principal del sistema de detecci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el detector y dependencias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Importar la clase principal del sistema de detecci√≥n\n",
    "from detector import ThreatDetector\n",
    "\n",
    "# Crear instancia del detector (inicialmente sin entrenar)\n",
    "detector = ThreatDetector()\n",
    "print(f\"¬øDetector entrenado? {detector.is_trained}\")\n",
    "\n",
    "# El detector maneja autom√°ticamente la inicializaci√≥n de modelos:\n",
    "# - KMeans para clustering de patrones normales\n",
    "# - LocalOutlierFactor (LOF) para detecci√≥n de outliers\n",
    "# - OneClassSVM para clasificaci√≥n de una clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-generation-section",
   "metadata": {},
   "source": [
    "## 3. Generaci√≥n de datos sint√©ticos\n",
    "\n",
    "**¬øQu√© hace esta secci√≥n?**\n",
    "- Crea funciones para generar datos de tr√°fico de red sint√©ticos\n",
    "- Simula patrones de tr√°fico normal y diferentes tipos de amenazas\n",
    "- Utiliza distribuciones estad√≠sticas realistas para cada tipo de tr√°fico\n",
    "\n",
    "**Tipos de tr√°fico simulado:**\n",
    "\n",
    "### Tr√°fico Normal\n",
    "- **Paquetes/segundo**: ~50 (distribuci√≥n normal)\n",
    "- **Bytes/segundo**: ~50,000 (distribuci√≥n normal)\n",
    "- **IPs √∫nicas**: 5-20 (variedad t√≠pica)\n",
    "- **Puertos √∫nicos**: 3-10 (aplicaciones comunes)\n",
    "- **Ratio TCP**: 60-80% (protocolo predominante)\n",
    "- **Paquetes SYN**: 10-50 (conexiones normales)\n",
    "\n",
    "### Amenazas Simuladas\n",
    "1. **DDoS**: Alto volumen de paquetes, pocas IPs origen\n",
    "2. **Port Scanning**: Muchos puertos √∫nicos, pocas IPs\n",
    "3. **Data Exfiltration**: Alto volumen de bytes, pocos puertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-generation-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos sint√©ticos: tr√°fico normal y anomal√≠as\n",
    "\n",
    "def gen_normal(n=300, seed=42):\n",
    "    \"\"\"\n",
    "    Genera datos de tr√°fico de red normal.\n",
    "    \n",
    "    Simula patrones t√≠picos de red empresarial con:\n",
    "    - Volumen moderado de tr√°fico\n",
    "    - Variabilidad natural en las m√©tricas\n",
    "    - Distribuciones gaussianas para realismo\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return [\n",
    "        {\n",
    "            'packets_per_second': float(rng.normal(50, 10)),      # Tr√°fico moderado\n",
    "            'bytes_per_second': float(rng.normal(50000, 10000)),  # ~50KB/s t√≠pico\n",
    "            'unique_ips': int(rng.integers(5, 20)),               # Diversidad normal\n",
    "            'unique_ports': int(rng.integers(3, 10)),             # Aplicaciones comunes\n",
    "            'tcp_ratio': float(rng.uniform(0.6, 0.8)),            # TCP predominante\n",
    "            'syn_packets': int(rng.integers(10, 50)),             # Conexiones normales\n",
    "        } for _ in range(n)\n",
    "    ]\n",
    "\n",
    "def gen_anomalies(n=60, seed=123):\n",
    "    \"\"\"\n",
    "    Genera datos de tr√°fico an√≥malo que representan diferentes amenazas.\n",
    "    \n",
    "    Tipos de amenazas simuladas:\n",
    "    - Modo 0 (DDoS): Alto volumen de paquetes, pocas IPs\n",
    "    - Modo 1 (Port Scan): Muchos puertos, pocas IPs  \n",
    "    - Modo 2 (Data Exfil): Alto volumen de bytes, pocos puertos\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        mode = rng.integers(0, 3)  # Seleccionar tipo de amenaza aleatoriamente\n",
    "        \n",
    "        if mode == 0:  # DDoS-like: volumen extremo, origen concentrado\n",
    "            d = {\n",
    "                'packets_per_second': float(rng.normal(2000, 200)),    # 40x m√°s paquetes\n",
    "                'bytes_per_second': float(rng.normal(2e6, 2e5)),       # 40x m√°s bytes\n",
    "                'unique_ips': int(rng.integers(1, 5)),                 # Pocas IPs origen\n",
    "                'unique_ports': int(rng.integers(1, 3)),               # Pocos puertos\n",
    "                'tcp_ratio': float(rng.uniform(0.7, 1.0)),             # Alto TCP\n",
    "                'syn_packets': int(rng.integers(500, 1200))            # Muchos SYN\n",
    "            }\n",
    "        elif mode == 1:  # Port-scan-like: exploraci√≥n de puertos\n",
    "            d = {\n",
    "                'packets_per_second': float(rng.normal(200, 30)),      # Tr√°fico moderado\n",
    "                'bytes_per_second': float(rng.normal(1e5, 2e4)),       # Bytes moderados\n",
    "                'unique_ips': int(rng.integers(1, 3)),                 # Pocas IPs origen\n",
    "                'unique_ports': int(rng.integers(30, 200)),            # MUCHOS puertos\n",
    "                'tcp_ratio': float(rng.uniform(0.4, 0.9)),             # TCP variable\n",
    "                'syn_packets': int(rng.integers(50, 150))              # SYN moderado\n",
    "            }\n",
    "        else:  # Exfiltration-like: transferencia masiva de datos\n",
    "            d = {\n",
    "                'packets_per_second': float(rng.normal(120, 20)),      # Tr√°fico moderado\n",
    "                'bytes_per_second': float(rng.normal(6e6, 5e5)),       # MUCHOS bytes\n",
    "                'unique_ips': int(rng.integers(1, 4)),                 # Pocas IPs\n",
    "                'unique_ports': int(rng.integers(1, 5)),               # Pocos puertos\n",
    "                'tcp_ratio': float(rng.uniform(0.85, 1.0)),            # Casi todo TCP\n",
    "                'syn_packets': int(rng.integers(20, 60))               # SYN normal\n",
    "            }\n",
    "        data.append(d)\n",
    "    return data\n",
    "\n",
    "# Generar datasets: 400 muestras normales + 80 anomal√≠as\n",
    "normal = gen_normal(400)\n",
    "anoms = gen_anomalies(80)\n",
    "print(f\"Generados: {len(normal)} muestras normales, {len(anoms)} anomal√≠as\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-section",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento del detector\n",
    "\n",
    "**¬øQu√© hace esta secci√≥n?**\n",
    "- Alimenta al detector con datos de tr√°fico normal √∫nicamente\n",
    "- Entrena los modelos de machine learning usando patrones normales\n",
    "- Verifica que el entrenamiento fue exitoso\n",
    "\n",
    "**Proceso de entrenamiento:**\n",
    "1. **Extracci√≥n de caracter√≠sticas**: Convierte datos crudos en vectores num√©ricos\n",
    "2. **Normalizaci√≥n**: Escala las caracter√≠sticas para optimizar el rendimiento\n",
    "3. **Entrenamiento de modelos**: Ajusta KMeans, LOF y OneClassSVM\n",
    "4. **Validaci√≥n**: Confirma que los modelos est√°n listos para detecci√≥n\n",
    "\n",
    "**¬øPor qu√© solo datos normales?**\n",
    "Los algoritmos de detecci√≥n de anomal√≠as aprenden qu√© es \"normal\" y detectan desviaciones de estos patrones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alimentar datos normales al detector y entrenar modelos\n",
    "\n",
    "print(\"Procesando datos normales...\")\n",
    "# El detector extrae caracter√≠sticas y las almacena internamente\n",
    "for i, d in enumerate(normal):\n",
    "    detector.extract_features(d)\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"Procesadas {i + 1}/{len(normal)} muestras\")\n",
    "\n",
    "print(\"\\nEntrenando modelos de machine learning...\")\n",
    "# Entrena KMeans, LOF y OneClassSVM con los datos normales acumulados\n",
    "detector.train_models()\n",
    "\n",
    "print(f\"‚úÖ Entrenamiento completado. Detector entrenado: {detector.is_trained}\")\n",
    "\n",
    "# Verificar que los modelos fueron entrenados correctamente\n",
    "print(f\"üìä Muestras de entrenamiento: {len(detector.features)}\")\n",
    "print(f\"üéØ Clusters KMeans: {detector.kmeans.n_clusters}\")\n",
    "print(f\"üîç Vecinos LOF: {detector.lof.n_neighbors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-prep-section",
   "metadata": {},
   "source": [
    "## 5. Preparaci√≥n de datos para visualizaci√≥n\n",
    "\n",
    "**¬øQu√© hace esta secci√≥n?**\n",
    "- Convierte los datos de tr√°fico a matrices num√©ricas para an√°lisis\n",
    "- Combina datos normales y an√≥malos en un dataset unificado\n",
    "- Aplica PCA para reducir dimensiones de 6D a 2D para visualizaci√≥n\n",
    "\n",
    "**Vector de caracter√≠sticas (6 dimensiones):**\n",
    "1. `packets_per_second`: Volumen de paquetes\n",
    "2. `bytes_per_second`: Volumen de datos  \n",
    "3. `unique_ips`: Diversidad de direcciones IP\n",
    "4. `unique_ports`: Diversidad de puertos\n",
    "5. `tcp_ratio`: Proporci√≥n de tr√°fico TCP\n",
    "6. `syn_packets`: N√∫mero de paquetes de inicio de conexi√≥n\n",
    "\n",
    "**¬øPor qu√© PCA?**\n",
    "PCA (Principal Component Analysis) nos permite visualizar datos multidimensionales en un gr√°fico 2D manteniendo la mayor variabilidad posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-prep-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir datos a matrices num√©ricas y aplicar PCA\n",
    "\n",
    "def to_vec(d):\n",
    "    \"\"\"Convierte un diccionario de m√©tricas de tr√°fico a vector num√©rico.\"\"\"\n",
    "    return [\n",
    "        d.get('packets_per_second', 0),    # Dimensi√≥n 0: Volumen de paquetes\n",
    "        d.get('bytes_per_second', 0),      # Dimensi√≥n 1: Volumen de bytes\n",
    "        d.get('unique_ips', 0),            # Dimensi√≥n 2: Diversidad de IPs\n",
    "        d.get('unique_ports', 0),          # Dimensi√≥n 3: Diversidad de puertos\n",
    "        d.get('tcp_ratio', 0.5),           # Dimensi√≥n 4: Proporci√≥n TCP\n",
    "        d.get('syn_packets', 0),           # Dimensi√≥n 5: Paquetes SYN\n",
    "    ]\n",
    "\n",
    "# Crear matrices de datos\n",
    "Xn = np.array([to_vec(d) for d in normal])    # 400 x 6: datos normales\n",
    "Xa = np.array([to_vec(d) for d in anoms])     # 80 x 6: datos an√≥malos\n",
    "X = np.vstack([Xn, Xa])                       # 480 x 6: dataset completo\n",
    "y = np.array([0]*len(Xn) + [1]*len(Xa))       # Etiquetas: 0=normal, 1=an√≥malo\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Normal: {len(Xn)} muestras, An√≥malos: {len(Xa)} muestras\")\n",
    "\n",
    "# Aplicar escalado usando el scaler del detector entrenado\n",
    "# Esto asegura consistencia con el modelo en producci√≥n\n",
    "Xs = detector.scaler.transform(X) if hasattr(detector.scaler, 'mean_') else X\n",
    "\n",
    "# Proyecci√≥n PCA: 6D ‚Üí 2D para visualizaci√≥n\n",
    "# PCA encuentra las 2 direcciones de mayor variabilidad en los datos\n",
    "pca = PCA(n_components=2, random_state=0)\n",
    "Z = pca.fit_transform(Xs)\n",
    "\n",
    "print(f\"Datos proyectados a 2D: {Z.shape}\")\n",
    "print(f\"Varianza explicada por PC1: {pca.explained_variance_ratio_[0]:.3f}\")\n",
    "print(f\"Varianza explicada por PC2: {pca.explained_variance_ratio_[1]:.3f}\")\n",
    "print(f\"Varianza total explicada: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "# Mostrar primeras muestras proyectadas\n",
    "print(f\"\\nPrimeras 3 muestras en espacio PCA:\")\n",
    "print(Z[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-basic-section",
   "metadata": {},
   "source": [
    "## 6. Visualizaci√≥n: Distribuci√≥n de datos normales vs an√≥malos\n",
    "\n",
    "**¬øQu√© hace esta visualizaci√≥n?**\n",
    "- Muestra la separaci√≥n entre tr√°fico normal y an√≥malo en el espacio 2D (PCA)\n",
    "- Usa colores para distinguir: azul = normal, rojo = an√≥malo\n",
    "- Permite evaluar visualmente qu√© tan separables son los patrones\n",
    "\n",
    "**¬øQu√© esperamos ver?**\n",
    "- **Datos normales (azul)**: Agrupados en una regi√≥n compacta\n",
    "- **Datos an√≥malos (rojo)**: Dispersos en regiones alejadas del cluster normal\n",
    "- **Separaci√≥n clara**: Indica que los algoritmos ML podr√°n distinguir amenazas\n",
    "\n",
    "**Interpretaci√≥n:**\n",
    "- Si hay solapamiento significativo ‚Üí detecci√≥n m√°s dif√≠cil\n",
    "- Si hay separaci√≥n clara ‚Üí detecci√≥n m√°s confiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization-basic-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n: distribuci√≥n de datos normales vs an√≥malos\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Crear scatter plot con colores diferenciados\n",
    "sns.scatterplot(x=Z[:,0], y=Z[:,1], hue=y, \n",
    "               palette={0: 'tab:blue', 1: 'tab:red'}, \n",
    "               s=30, alpha=0.7)\n",
    "\n",
    "# Personalizar el gr√°fico\n",
    "plt.title('Proyecci√≥n PCA: Tr√°fico Normal vs Amenazas', fontsize=14, fontweight='bold')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} varianza)', fontsize=12)\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} varianza)', fontsize=12)\n",
    "\n",
    "# Personalizar leyenda\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, ['Normal', 'Amenaza'], title='Tipo de Tr√°fico', \n",
    "          title_fontsize=12, fontsize=11)\n",
    "\n",
    "# Agregar grid para mejor lectura\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estad√≠sticas de separaci√≥n\n",
    "normal_center = Z[y==0].mean(axis=0)\n",
    "anomaly_center = Z[y==1].mean(axis=0)\n",
    "separation_distance = np.linalg.norm(normal_center - anomaly_center)\n",
    "\n",
    "print(f\"üìç Centro datos normales: PC1={normal_center[0]:.2f}, PC2={normal_center[1]:.2f}\")\n",
    "print(f\"üìç Centro datos an√≥malos: PC1={anomaly_center[0]:.2f}, PC2={anomaly_center[1]:.2f}\")\n",
    "print(f\"üìè Distancia de separaci√≥n: {separation_distance:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kmeans-section",
   "metadata": {},
   "source": [
    "## 7. An√°lisis de clustering con KMeans\n",
    "\n",
    "**¬øQu√© hace esta visualizaci√≥n?**\n",
    "- Muestra c√≥mo KMeans agrupa los datos en clusters\n",
    "- Visualiza los centros de los clusters como marcas X negras\n",
    "- Colorea cada punto seg√∫n su asignaci√≥n de cluster\n",
    "\n",
    "**¬øC√≥mo funciona KMeans en el detector?**\n",
    "1. **Entrenamiento**: Solo con datos normales, identifica patrones comunes\n",
    "2. **Clustering**: Agrupa datos similares en K clusters (t√≠picamente K=3-5)\n",
    "3. **Detecci√≥n**: Calcula distancia de nuevas muestras a centros de clusters\n",
    "4. **Umbral**: Si distancia > umbral ‚Üí posible amenaza\n",
    "\n",
    "**¬øQu√© buscamos?**\n",
    "- **Datos normales**: Cerca de los centros de clusters\n",
    "- **Datos an√≥malos**: Lejos de todos los centros de clusters\n",
    "- **Centros**: Representan los patrones t√≠picos de tr√°fico normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kmeans-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de clusters KMeans y sus centros\n",
    "\n",
    "# Obtener asignaciones de cluster para todos los datos\n",
    "labels = detector.kmeans.predict(Xs)\n",
    "\n",
    "# Proyectar centros de clusters de 6D a 2D para visualizaci√≥n\n",
    "centers_6d = detector.kmeans.cluster_centers_  # Centros en espacio original\n",
    "centers_2d = pca.transform(centers_6d)         # Centros proyectados a PCA\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot coloreado por cluster asignado\n",
    "sns.scatterplot(x=Z[:,0], y=Z[:,1], hue=labels, \n",
    "               palette='tab10', s=25, alpha=0.7, legend=False)\n",
    "\n",
    "# Marcar centros de clusters\n",
    "plt.scatter(centers_2d[:,0], centers_2d[:,1], \n",
    "           c='black', s=200, marker='x', linewidths=3,\n",
    "           label='Centros de Clusters', zorder=5)\n",
    "\n",
    "# Personalizar gr√°fico\n",
    "plt.title('KMeans: Clustering de Patrones de Tr√°fico', fontsize=14, fontweight='bold')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} varianza)', fontsize=12)\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} varianza)', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lisis de cluster assignments\n",
    "print(\"üìä An√°lisis de asignaciones de cluster:\")\n",
    "for cluster_id in range(detector.kmeans.n_clusters):\n",
    "    cluster_mask = labels == cluster_id\n",
    "    normal_in_cluster = np.sum(cluster_mask[:len(Xn)])\n",
    "    anomaly_in_cluster = np.sum(cluster_mask[len(Xn):])\n",
    "    total_in_cluster = np.sum(cluster_mask)\n",
    "    \n",
    "    print(f\"Cluster {cluster_id}: {total_in_cluster} muestras \"\n",
    "          f\"({normal_in_cluster} normales, {anomaly_in_cluster} an√≥malas)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heatmaps-section",
   "metadata": {},
   "source": [
    "## 8. Mapas de calor: LOF y One-Class SVM\n",
    "\n",
    "**¬øQu√© hace esta secci√≥n?**\n",
    "- Crea mapas de calor mostrando las \"puntuaciones de decisi√≥n\" de cada algoritmo\n",
    "- Visualiza c√≥mo cada modelo ve el espacio de caracter√≠sticas\n",
    "- Compara las regiones que cada algoritmo considera normales vs an√≥malas\n",
    "\n",
    "**Local Outlier Factor (LOF):**\n",
    "- **Funci√≥n**: Detecta outliers bas√°ndose en densidad local\n",
    "- **Interpretaci√≥n**: Valores positivos = normal, negativos = outlier\n",
    "- **Visualizaci√≥n**: Mapa de calor donde rojo = m√°s an√≥malo\n",
    "\n",
    "**One-Class SVM:**\n",
    "- **Funci√≥n**: Crea una frontera alrededor de datos normales\n",
    "- **Interpretaci√≥n**: Valores positivos = dentro de la frontera (normal)\n",
    "- **Visualizaci√≥n**: Mapa de calor donde verde = normal, p√∫rpura = an√≥malo\n",
    "\n",
    "**¬øC√≥mo leer los mapas?**\n",
    "- **Regiones claras**: Donde el modelo es muy confiado en su decisi√≥n\n",
    "- **Regiones de transici√≥n**: Donde el modelo es menos seguro\n",
    "- **Puntos superpuestos**: Nuestros datos reales para validar las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heatmaps-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapas de calor de algoritmos de detecci√≥n: LOF y One-Class SVM\n",
    "\n",
    "def grid_scores(model_decision_fn, Z_data, steps=120):\n",
    "    \"\"\"\n",
    "    Crea una grilla 2D y calcula scores de decisi√≥n para visualizaci√≥n.\n",
    "    \n",
    "    Args:\n",
    "        model_decision_fn: Funci√≥n de decisi√≥n del modelo\n",
    "        Z_data: Datos proyectados en 2D (PCA)\n",
    "        steps: Resoluci√≥n de la grilla\n",
    "    \n",
    "    Returns:\n",
    "        xx, yy: Coordenadas de la grilla\n",
    "        zz: Scores de decisi√≥n en cada punto de la grilla\n",
    "    \"\"\"\n",
    "    # Definir l√≠mites de la grilla basados en los datos\n",
    "    x_min, x_max = Z_data[:,0].min()-1, Z_data[:,0].max()+1\n",
    "    y_min, y_max = Z_data[:,1].min()-1, Z_data[:,1].max()+1\n",
    "    \n",
    "    # Crear grilla uniforme\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, steps), \n",
    "                         np.linspace(y_min, y_max, steps))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    # Convertir de PCA 2D de vuelta a espacio 6D escalado\n",
    "    Xs_grid = pca.inverse_transform(grid)\n",
    "    \n",
    "    # Calcular scores de decisi√≥n y reformatear para visualizaci√≥n\n",
    "    zz = model_decision_fn(Xs_grid).reshape(xx.shape)\n",
    "    return xx, yy, zz\n",
    "\n",
    "# === LOCAL OUTLIER FACTOR (LOF) ===\n",
    "print(\"üîç Generando mapa de calor para Local Outlier Factor...\")\n",
    "xx, yy, zz_lof = grid_scores(lambda Xs_: detector.lof.decision_function(Xs_), Z)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Subplot 1: LOF decision function\n",
    "plt.subplot(1, 2, 1)\n",
    "contour = plt.contourf(xx, yy, zz_lof, levels=20, cmap='coolwarm', alpha=0.8)\n",
    "scatter = plt.scatter(Z[:,0], Z[:,1], c=y, cmap='bwr', s=20, \n",
    "                     edgecolor='white', linewidth=0.5, alpha=0.8)\n",
    "plt.colorbar(contour, label='LOF Score (+ = normal, - = outlier)')\n",
    "plt.title('LOF: Detecci√≥n basada en Densidad Local', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('PC1'); plt.ylabel('PC2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# === ONE-CLASS SVM ===\n",
    "print(\"üéØ Generando mapa de calor para One-Class SVM...\")\n",
    "xx, yy, zz_svm = grid_scores(lambda Xs_: detector.svm.decision_function(Xs_), Z)\n",
    "\n",
    "# Subplot 2: One-Class SVM\n",
    "plt.subplot(1, 2, 2)\n",
    "contour = plt.contourf(xx, yy, zz_svm, levels=20, cmap='PiYG', alpha=0.8)\n",
    "scatter = plt.scatter(Z[:,0], Z[:,1], c=y, cmap='bwr', s=20, \n",
    "                     edgecolor='white', linewidth=0.5, alpha=0.8)\n",
    "plt.colorbar(contour, label='SVM Score (+ = normal, - = outlier)')\n",
    "plt.title('One-Class SVM: Frontera de Decisi√≥n', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('PC1'); plt.ylabel('PC2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estad√≠sticas de los modelos\n",
    "print(\"\\nüìà Estad√≠sticas de los algoritmos:\")\n",
    "lof_scores = detector.lof.decision_function(Xs)\n",
    "svm_scores = detector.svm.decision_function(Xs)\n",
    "\n",
    "print(f\"LOF - Normal promedio: {lof_scores[:len(Xn)].mean():.3f}, \"\n",
    "      f\"An√≥malo promedio: {lof_scores[len(Xn):].mean():.3f}\")\n",
    "print(f\"SVM - Normal promedio: {svm_scores[:len(Xn)].mean():.3f}, \"\n",
    "      f\"An√≥malo promedio: {svm_scores[len(Xn):].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "testing-section",
   "metadata": {},
   "source": [
    "## 9. Pruebas de detecci√≥n en tiempo real\n",
    "\n",
    "**¬øQu√© hace esta secci√≥n?**\n",
    "- Prueba el endpoint de detecci√≥n del sistema con muestras espec√≠ficas\n",
    "- Compara una muestra normal vs una muestra an√≥mala\n",
    "- Muestra la respuesta completa del sistema incluyendo confianza y tipos de amenaza\n",
    "\n",
    "**Componentes de la respuesta:**\n",
    "- **threat_detected**: Boolean indicando si se detect√≥ amenaza\n",
    "- **confidence**: Nivel de confianza (0.0-1.0)\n",
    "- **threat_types**: Lista de tipos de amenaza detectados\n",
    "- **scores**: Detalles de puntuaci√≥n por m√©todo (reglas + ML)\n",
    "\n",
    "**Tipos de amenaza que puede detectar:**\n",
    "- `ddos`: Ataques de denegaci√≥n de servicio\n",
    "- `port_scan`: Escaneo de puertos\n",
    "- `data_exfil`: Exfiltraci√≥n de datos\n",
    "- `ml_high_risk`, `ml_medium_risk`: Clasificaciones por ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "testing-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruebas de detecci√≥n usando el endpoint interno del detector\n",
    "\n",
    "# Seleccionar muestras representativas para testing\n",
    "test_normal = normal[0]      # Primera muestra normal\n",
    "test_anomaly = anoms[0]      # Primera muestra an√≥mala\n",
    "\n",
    "samples = [\n",
    "    (\"üü¢ TR√ÅFICO NORMAL\", test_normal),\n",
    "    (\"üî¥ TR√ÅFICO AN√ìMALO\", test_anomaly)\n",
    "]\n",
    "\n",
    "print(\"üß™ PRUEBAS DE DETECCI√ìN EN TIEMPO REAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for label, sample in samples:\n",
    "    print(f\"\\n{label}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Mostrar m√©tricas de entrada\n",
    "    print(\"üìä M√©tricas de entrada:\")\n",
    "    for key, value in sample.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {key}: {value:.2f}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Ejecutar detecci√≥n\n",
    "    result = detector.detect(sample)\n",
    "    \n",
    "    # Mostrar resultado de detecci√≥n\n",
    "    print(f\"\\nüéØ Resultado de detecci√≥n:\")\n",
    "    print(f\"  Amenaza detectada: {'S√ç' if result['threat_detected'] else 'NO'}\")\n",
    "    print(f\"  Nivel de confianza: {result['confidence']:.2f}\")\n",
    "    \n",
    "    if result['threat_types']:\n",
    "        print(f\"  Tipos de amenaza: {', '.join(result['threat_types'])}\")\n",
    "    \n",
    "    if result['scores']:\n",
    "        print(f\"  Scores detallados:\")\n",
    "        for method, score in result['scores'].items():\n",
    "            print(f\"    {method}: {score}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# An√°lisis de rendimiento r√°pido\n",
    "print(\"\\nüìà AN√ÅLISIS DE RENDIMIENTO R√ÅPIDO\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Probar con m√°s muestras para estad√≠sticas\n",
    "test_samples = normal[:10] + anoms[:10]\n",
    "test_labels = [0]*10 + [1]*10\n",
    "\n",
    "correct_detections = 0\n",
    "for i, (sample, expected) in enumerate(zip(test_samples, test_labels)):\n",
    "    result = detector.detect(sample)\n",
    "    detected = 1 if result['threat_detected'] else 0\n",
    "    if detected == expected:\n",
    "        correct_detections += 1\n",
    "\n",
    "accuracy = correct_detections / len(test_samples)\n",
    "print(f\"Precisi√≥n en muestra peque√±a: {accuracy:.2f} ({correct_detections}/{len(test_samples)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions-section",
   "metadata": {},
   "source": [
    "## üéâ Conclusiones del an√°lisis\n",
    "\n",
    "### Lo que hemos aprendido:\n",
    "\n",
    "1. **Separabilidad de datos**: Los algoritmos pueden distinguir entre tr√°fico normal y an√≥malo\n",
    "2. **Efectividad de modelos**: Cada algoritmo (KMeans, LOF, SVM) aporta una perspectiva diferente\n",
    "3. **Visualizaci√≥n PCA**: Permite entender c√≥mo \"ve\" el sistema los patrones de tr√°fico\n",
    "4. **Sistema h√≠brido**: Combina reglas determin√≠sticas con machine learning para mayor precisi√≥n\n",
    "\n",
    "### Pr√≥ximos pasos para mejorar:\n",
    "\n",
    "- **Datos reales**: Reemplazar datos sint√©ticos con tr√°fico real capturado por eBPF\n",
    "- **Ajuste de hiperpar√°metros**: Optimizar configuraciones de los modelos\n",
    "- **Nuevas caracter√≠sticas**: Agregar m√©tricas adicionales (latencia, protocolos, etc.)\n",
    "- **Evaluaci√≥n completa**: M√©tricas de precision, recall, F1-score con datasets m√°s grandes\n",
    "\n",
    "### Uso en producci√≥n:\n",
    "\n",
    "El detector entrenado se integra con:\n",
    "- **eBPF Monitor**: Captura m√©tricas de red en tiempo real\n",
    "- **API REST**: Endpoint `/detect` para evaluaci√≥n de tr√°fico\n",
    "- **Prometheus**: M√©tricas de rendimiento y alertas\n",
    "- **Grafana**: Dashboards de visualizaci√≥n y monitoreo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}